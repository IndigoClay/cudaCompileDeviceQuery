{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cudaCompileDeviceQuery.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjHXBcI8U0qCHHhHjEuqvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndigoClay/cudaCompileDeviceQuery/blob/main/cudaCompileDeviceQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDLwIDPw7H4X",
        "outputId": "e615befe-8b72-4e09-97fb-818ab9c150d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Thu Mar 31 12:38:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IndigoClay/cudaCompileDeviceQuery.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF0tTH9BhIrO",
        "outputId": "9a4f5ac4-e1c6-4d70-90b1-50a8c42a6dcf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cudaCompileDeviceQuery'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 22 (delta 6), reused 16 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "nWBt2To_7QhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/IndigoClay/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JywImrhB7VQi",
        "outputId": "083d3b3f-5d8b-4710-c956-5e6a54f69b71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/IndigoClay/nvcc4jupyter.git\n",
            "  Cloning https://github.com/IndigoClay/nvcc4jupyter.git to /tmp/pip-req-build-77xjwnhl\n",
            "  Running command git clone -q https://github.com/IndigoClay/nvcc4jupyter.git /tmp/pip-req-build-77xjwnhl\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4286 sha256=22c801c020c2e4ce0372b29798840b483c739ceacafc28f769514cd0817c3e28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4pyg8qsp/wheels/c4/52/63/f7029f491c28a55cf4cb96d4abbcb3460592100edbd8560c5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JTC5foM7cEs",
        "outputId": "5f733bf4-9523-4cb3-f2f9-e53496a1db0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define NUM_BLOCKS 16\n",
        "#define BLOCK_WIDTH 1\n",
        "\n",
        "__global__ void hello()\n",
        "{\n",
        "    printf(\"Hello world! I'm a thread in block %d\\n\", blockIdx.x);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "    // launch the kernel\n",
        "    hello<<<NUM_BLOCKS, BLOCK_WIDTH>>>();\n",
        "\n",
        "    // force the printf()s to flush\n",
        "    cudaDeviceSynchronize();\n",
        "    \n",
        "    printf(\"That's all!\\n\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "T7Ib0iaT7hti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/cudaCompileDeviceQuery && pwd && make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCUgtYbm_XHA",
        "outputId": "378b9596-505e-424c-b548-8d026c82f0a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cudaCompileDeviceQuery\n",
            "make: Nothing to be done for 'all'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./cudaCompileDeviceQuery/deviceQuery"
      ],
      "metadata": {
        "id": "pQxbfcx-LE46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNl9A7giN-GO",
        "outputId": "b52ae9be-f6a5-4d03-aa58-5a776389a6d6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "//demonstating the usage of global memory\n",
        "\n",
        "using namespace std;\n",
        "__global__ void use_global_memory_GPU(float *array)\n",
        "{\n",
        "    array[threadIdx.x] = 3.14f * (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    float h_arr[128];\n",
        "    float *d_arr;\n",
        " \n",
        "    cudaMalloc((void **)&d_arr, sizeof(float)*128);\n",
        "    cudaMemcpy((void *)d_arr, (void *)h_arr, sizeof(float)*128, cudaMemcpyHostToDevice);\n",
        " \n",
        "    use_global_memory_GPU<<<1, 128>>>(d_arr);\n",
        "    cudaMemcpy((void *)h_arr, (void *)d_arr, sizeof(float)*128, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_arr);\n",
        "    for (auto const& i : h_arr) {\n",
        "      cout << i << \"  \";\n",
        "    }\n",
        "    cout << h_arr[2];\n",
        "    //system(\"ls\");\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlh0a8voHIG0",
        "outputId": "944f0366-219a-4caf-e286-b5cbc051de7a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  3.14  6.28  9.42  12.56  15.7  18.84  21.98  25.12  28.26  31.4  34.54  37.68  40.82  43.96  47.1  50.24  53.38  56.52  59.66  62.8  65.94  69.08  72.22  75.36  78.5  81.64  84.78  87.92  91.06  94.2  97.34  100.48  103.62  106.76  109.9  113.04  116.18  119.32  122.46  125.6  128.74  131.88  135.02  138.16  141.3  144.44  147.58  150.72  153.86  157  160.14  163.28  166.42  169.56  172.7  175.84  178.98  182.12  185.26  188.4  191.54  194.68  197.82  200.96  204.1  207.24  210.38  213.52  216.66  219.8  222.94  226.08  229.22  232.36  235.5  238.64  241.78  244.92  248.06  251.2  254.34  257.48  260.62  263.76  266.9  270.04  273.18  276.32  279.46  282.6  285.74  288.88  292.02  295.16  298.3  301.44  304.58  307.72  310.86  314  317.14  320.28  323.42  326.56  329.7  332.84  335.98  339.12  342.26  345.4  348.54  351.68  354.82  357.96  361.1  364.24  367.38  370.52  373.66  376.8  379.94  383.08  386.22  389.36  392.5  395.64  398.78  6.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include \"/content/cudaCompileDeviceQuery/GpuTimer.h\"\n",
        "using namespace std;\n",
        "\n",
        "//demonstating the usage of global and shared memory and the start of 2 kernels\n",
        "__global__ void use_global_memory_GPU(float *array)\n",
        "{\n",
        "    array[threadIdx.x] = 1.0f * (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void use_shared_memory_GPU(float *array)\n",
        "{\n",
        "   \n",
        "    int i, index = threadIdx.x;\n",
        "    float average, sum = 0.0f;\n",
        " \n",
        "    __shared__ float sh_arr[128];\n",
        "    \n",
        "    // copy data from global array to shared array\n",
        "    sh_arr[index] = array[index];\n",
        " \n",
        "    __syncthreads();\n",
        " \n",
        "    // sum up values until own index\n",
        "    for (i=0; i<=index; i++) {\n",
        "        sum += sh_arr[i];\n",
        "    }\n",
        "    // the average = sum/NumElements = sum/index\n",
        "    average = sum / (index+1.0f);\n",
        "    //array[index] = sum;\n",
        "    if(array[index] > average) { array[index] = average;}\n",
        "}\n",
        "\n",
        "int main(int argc, char argv)\n",
        "{\n",
        "    GpuTimer timer;\n",
        "    float h_arr[128];\n",
        "    float *d_arr;\n",
        " \n",
        "    cudaMalloc((void **)&d_arr, sizeof(float)*128);\n",
        "    cudaMemcpy((void *)d_arr, (void *)h_arr, sizeof(float)*128, cudaMemcpyHostToDevice);\n",
        " \n",
        "    use_global_memory_GPU<<<1, 128>>>(d_arr);\n",
        "    cudaMemcpy((void *)h_arr, (void *)d_arr, sizeof(float)*128, cudaMemcpyDeviceToHost);\n",
        "     for (auto const& i : h_arr) {\n",
        "      cout << i << \"  \";\n",
        "    }\n",
        "    cout << endl;\n",
        "    cudaMemcpy((void *)d_arr, (void *)h_arr, sizeof(float)*128, cudaMemcpyHostToDevice);\n",
        "    timer.Start();\n",
        "    use_shared_memory_GPU<<<1, 128>>>(d_arr);\n",
        "    timer.Stop();\n",
        "    cudaMemcpy((void *)h_arr, (void *)d_arr, sizeof(float)*128, cudaMemcpyDeviceToHost);\n",
        "    for (auto const& i : h_arr) {\n",
        "      cout << i << \"  \";\n",
        "    }\n",
        "    cout << endl;\n",
        "    printf(\"Time elapsed = %g ms\", timer.Elapsed());\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "   \n",
        "    //system(\"ls\");\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S39XMVCrI14_",
        "outputId": "f680cc86-88e1-4db3-ac79-d6d3b394e02e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  \n",
            "0  0.5  1  1.5  2  2.5  3  3.5  4  4.5  5  5.5  6  6.5  7  7.5  8  8.5  9  9.5  10  10.5  11  11.5  12  12.5  13  13.5  14  14.5  15  15.5  16  16.5  17  17.5  18  18.5  19  19.5  20  20.5  21  21.5  22  22.5  23  23.5  24  24.5  25  25.5  26  26.5  27  27.5  28  28.5  29  29.5  30  30.5  31  31.5  32  32.5  33  33.5  34  34.5  35  35.5  36  36.5  37  37.5  38  38.5  39  39.5  40  40.5  41  41.5  42  42.5  43  43.5  44  44.5  45  45.5  46  46.5  47  47.5  48  48.5  49  49.5  50  50.5  51  51.5  52  52.5  53  53.5  54  54.5  55  55.5  56  56.5  57  57.5  58  58.5  59  59.5  60  60.5  61  61.5  62  62.5  63  63.5  \n",
            "Time elapsed = 0.025376 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include \"/content/cudaCompileDeviceQuery/GpuTimer.h\"\n",
        "\n",
        "#define NUM_THREADS 1000000\n",
        "#define ARRAY_SIZE  100\n",
        "\n",
        "#define BLOCK_WIDTH 1000\n",
        "\n",
        "void print_array(int *array, int size)\n",
        "{\n",
        "    printf(\"{ \");\n",
        "    for (int i = 0; i < size; i++)  { printf(\"%d \", array[i]); }\n",
        "    printf(\"}\\n\");\n",
        "}\n",
        "\n",
        "__global__ void increment_naive(int *g)\n",
        "{\n",
        "\t// which thread is this?\n",
        "\tint i = blockIdx.x * blockDim.x + threadIdx.x; \n",
        "\n",
        "\t// each thread to increment consecutive elements, wrapping at ARRAY_SIZE\n",
        "\ti = i % ARRAY_SIZE;  \n",
        "\tg[i] = g[i] + 1;\n",
        "}\n",
        "\n",
        "__global__ void increment_atomic(int *g)\n",
        "{\n",
        "\t// which thread is this?\n",
        "\tint i = blockIdx.x * blockDim.x + threadIdx.x; \n",
        "\n",
        "\t// each thread to increment consecutive elements, wrapping at ARRAY_SIZE\n",
        "\ti = i % ARRAY_SIZE;  \n",
        "\tatomicAdd(& g[i], 1);\n",
        "}\n",
        "\n",
        "int main(int argc,char **argv)\n",
        "{   \n",
        "    GpuTimer timer;\n",
        "    printf(\"%d total threads in %d blocks writing into %d array elements\\n\",\n",
        "           NUM_THREADS, NUM_THREADS / BLOCK_WIDTH, ARRAY_SIZE);\n",
        "\n",
        "    // declare and allocate host memory\n",
        "    int h_array[ARRAY_SIZE];\n",
        "    const int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
        " \n",
        "    // declare, allocate, and zero out GPU memory\n",
        "    int * d_array;\n",
        "    cudaMalloc((void **) &d_array, ARRAY_BYTES);\n",
        "    cudaMemset((void *) d_array, 0, ARRAY_BYTES); \n",
        "\n",
        "    // launch the kernel - comment out one of these\n",
        "    timer.Start();\n",
        "    \n",
        "    // Instructions: This program is needed for the next quiz\n",
        "    // uncomment increment_naive to measure speed and accuracy \n",
        "    // of non-atomic increments or uncomment increment_atomic to\n",
        "    // measure speed and accuracy of  atomic icrements\n",
        "    increment_naive<<<NUM_THREADS/BLOCK_WIDTH, BLOCK_WIDTH>>>(d_array);\n",
        "    //increment_atomic<<<NUM_THREADS/BLOCK_WIDTH, BLOCK_WIDTH>>>(d_array);\n",
        "    timer.Stop();\n",
        "    \n",
        "    // copy back the array of sums from GPU and print\n",
        "    cudaMemcpy(h_array, d_array, ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
        "    print_array(h_array, ARRAY_SIZE);\n",
        "    printf(\"Time elapsed = %g ms\\n\", timer.Elapsed());\n",
        " \n",
        "    // free GPU memory allocation and exit\n",
        "    cudaFree(d_array);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u_-vKl0aa7g",
        "outputId": "e264e416-daa7-4aeb-fc86-7605803a6c5b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000 total threads in 1000 blocks writing into 100 array elements\n",
            "{ 55 55 55 55 56 56 56 56 58 58 58 58 58 58 58 58 57 57 57 57 56 56 56 56 56 56 56 56 59 59 59 59 67 67 67 67 63 63 63 63 63 63 63 63 57 57 57 57 57 57 57 57 58 58 58 58 61 61 61 61 53 53 53 53 52 52 52 52 51 51 51 51 51 51 51 51 47 47 47 47 48 48 48 48 48 48 48 48 52 52 52 52 52 52 52 52 54 54 54 54 }\n",
            "Time elapsed = 0.707296 ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jT2R9rwebrfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}